--
-- Host: localhost    Database: project
-- ------------------------------------------------------
-- Server version	5.6.10

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;


DROP TABLE IF EXISTS `bug_job_map`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;


--
-- Table structure for table `bug_job_map`
--

/**************************
 * Table: bug_job_map
 *
 * Maps job_ids to related bug_ids. Mappings can be made manually through a UI or from
 * doing lookups in the treeherder_reference_1.bugscache
 *
 * Population Method: scheduled job, manual by admin
 *
 * Example Data:
 *
 *  job_id - Referenced job.id
 *  bug_id - References bugzilla bug id
 *  type - parsing-suggestion (automatically generated) | annotation (manual assignment through UI)
 **************************/
CREATE TABLE `bug_job_map` (
  `job_id` bigint(20) unsigned NOT NULL,
  `bug_id` int(10) unsigned NOT NULL,
  `type` varchar(50) COLLATE utf8_bin NOT NULL,
  `submit_timestamp` int(10) unsigned NOT NULL,
  `who` varchar(50) COLLATE utf8_bin NOT NULL,
  `active_status` enum('active','onhold','deleted') COLLATE utf8_bin DEFAULT 'active',
  UNIQUE KEY `uni_job_id_bug_id` (`job_id`,`bug_id`),
  KEY `idx_job_id` (`job_id`),
  KEY `idx_bug_id` (`bug_id`),
  KEY `idx_type` (`type`),
  KEY `idx_who` (`who`),
  KEY `idx_submit_timestamp` (`submit_timestamp`),
  KEY `idx_active_status` (`active_status`),
  CONSTRAINT `fk_bug_job` FOREIGN KEY (`job_id`) REFERENCES `job` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Table structure for table `job`
--

DROP TABLE IF EXISTS `job`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;

/**************************
 * Table: job
 *
 * The core job results table. Holds all build and test result data and associated
 * data mappings.
 *
 * Population Method: dynamic from incoming data
 *
 * Example Data:
 *
 *  job_guid - A unique identifier of a job or any type. For buildbot generated data
 *             the guid is a hash of associated request_ids and a timestamp.
 *
 *  job_coalesced_to_guid - If present the job was coalesced to this job_guid
 *  signature - If populated, references treeherder_reference_1.buildbot_buildernames.signature
 *  result_set_id - References result_set.id
 *  build_platform_id - References treeherder_reference_1.build_platform.id
 *  machine_platform_id - References treeherder_reference_1.machine_platform.id
 *  machine_id - References treeherder_reference_1.machine.id
 *  option_collection_hash - References treeherder_reference_1.option_collection.option_collection_hash
 *  job_type_id - References treeherder_reference_1.job_type.id
 *  product_id - References treeherder_reference_1.product.id
 *  failure_classification_id - References treeherder_reference_1.failure_classification.id
 *  who - Description of who submitted the job: gaia | scheduler name | username
 *  reason - Reason for the job: push | scheduled | self-serve | manual
 *  result - Job outcome description: success | failure | ...
 *  state - Current state of job: pending | running | completed | coalesced | ...
 *  submit_timestamp - Time the job was submitted.
 *  start_timestamp - Time the job was started.
 *  end_timestamp - Time the job completed.
 *  last_modified - The last time the job was modified
 *  running_eta - ETA to a completed state. A rolling average over a 6 hr window of end_timestamp - start_timestamp, recomputed every 30 min.
 **************************/
CREATE TABLE `job` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `job_guid` varchar(50) COLLATE utf8_bin NOT NULL,
  `signature` varchar(50) DEFAULT NULL,
  `job_coalesced_to_guid` varchar(50) COLLATE utf8_bin DEFAULT NULL,
  `result_set_id` bigint(20) unsigned NOT NULL,
  `build_platform_id` int(10) unsigned NOT NULL,
  `machine_platform_id` int(10) unsigned NOT NULL,
  `machine_id` int(10) unsigned DEFAULT NULL,
  `device_id` int(10) unsigned DEFAULT NULL,
  `option_collection_hash` varchar(64) COLLATE utf8_bin DEFAULT NULL,
  `job_type_id` int(10) unsigned NOT NULL,
  `product_id` int(10) unsigned DEFAULT NULL,
  `failure_classification_id` int(10) unsigned DEFAULT 1,
  `who` varchar(50) COLLATE utf8_bin NOT NULL,
  `reason` varchar(125) COLLATE utf8_bin NOT NULL,
  `result` varchar(25) COLLATE utf8_bin DEFAULT NULL,
  `state` varchar(25) COLLATE utf8_bin NOT NULL,
  `submit_timestamp` int(10) unsigned NOT NULL,
  `start_timestamp` int(10) unsigned DEFAULT NULL,
  `end_timestamp` int(10) unsigned DEFAULT NULL,
  `last_modified` TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  `running_eta` int(10) unsigned DEFAULT NULL,
  `tier` int(10) unsigned DEFAULT 1,
  `active_status` enum('active','onhold','deleted') COLLATE utf8_bin DEFAULT 'active',
  PRIMARY KEY (`id`),
  KEY `idx_job_guid` (`job_guid`),
  KEY `idx_job_coalesced_to_guid` (`job_coalesced_to_guid`),
  KEY `idx_signature` (`signature`),
  KEY `idx_result_set_id` (`result_set_id`),
  KEY `idx_build_platform_id` (`build_platform_id`),
  KEY `idx_machine_platform_id` (`machine_platform_id`),
  KEY `idx_machine_id` (`machine_id`),
  KEY `idx_device_id` (`device_id`),
  KEY `idx_option_collection_hash` (`option_collection_hash`),
  KEY `idx_job_type_id` (`job_type_id`),
  KEY `idx_product_id` (`product_id`),
  KEY `idx_failure_classification_id` (`failure_classification_id`),
  KEY `idx_who` (`who`),
  KEY `idx_reason` (`reason`),
  KEY `idx_result` (`result`),
  KEY `idx_state` (`state`),
  KEY `idx_submit_timestamp` (`submit_timestamp`),
  KEY `idx_start_timestamp` (`start_timestamp`),
  KEY `idx_end_timestamp` (`end_timestamp`),
  KEY `idx_last_modified` (`last_modified`),
  KEY `idx_running` (`running_eta`),
  KEY `idx_tier` (`tier`),
  KEY `idx_active_status` (`active_status`),
  CONSTRAINT `fk_result_set` FOREIGN KEY (`result_set_id`) REFERENCES `result_set` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;
/*!40101 SET character_set_client = @saved_cs_client */;

DROP TABLE IF EXISTS `job_eta`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
--
-- Table structure for table `job_eta`
--
/*************************
 * Table: job_eta
 *
 * This table holds a timeline of eta trends for pending and running jobs
 *
 * Population Method: dynamic from incoming data
 *
 * Example Data:
 *
 *  signature - References treeherder_reference_1.buildbot_buildernames.signature
 *  state - pending | running
 *  avg_sec - A rolling average over a 12 hr window in seconds
 *  median_sec - The median of the sample range
 *  min_sec - The minimum value of the sample range
 *  max_sec - The minimum value of the sample range
 *  std - Of the of avg_sec
 *  sample_count - The number of samples used in the rolling average
 *  submit_timestamp - The timestamp the eta data was computed and entered
 *************************/
CREATE TABLE `job_eta` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `signature` varchar(50) DEFAULT NULL,
  `state` varchar(25) COLLATE utf8_bin NOT NULL,
  `avg_sec` int(10) unsigned NOT NULL,
  `median_sec` int(10) unsigned NOT NULL,
  `min_sec` int(10) unsigned NOT NULL,
  `max_sec` int(10) unsigned NOT NULL,
  `std` int(10) unsigned NOT NULL,
  `sample_count` int(10) unsigned NOT NULL,
  `submit_timestamp` int(10) unsigned NOT NULL,
  PRIMARY KEY (`id`),
  KEY `idx_state` (`state`),
  KEY `idx_avg_sec` (`avg_sec`),
  KEY `idx_median_sec` (`median_sec`),
  KEY `idx_sample_count` (`sample_count`),
  KEY `idx_submit_timestamp` (`submit_timestamp`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Table structure for table `job_artifact`
--

DROP TABLE IF EXISTS `job_artifact`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;

/**************************
 * Table: job_artifact
 *
 *  Holds any kind of data associated with a job. Data can be structured in the
 *  case of JSON data or raw binary in the case of an image.
 *
 * Population Method: dynamic from incoming data
 *
 * Example Data:
 *
 *  job_id - References job.id
 *  name - Name of artifact data.
 *  type - json | img | ...
 *  blob - Artifact data
 **************************/
CREATE TABLE `job_artifact` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `job_id` bigint(20) unsigned NOT NULL,
  `name` varchar(50) COLLATE utf8_bin NOT NULL,
  `type` varchar(50) COLLATE utf8_bin NOT NULL,
  `blob` mediumblob NOT NULL,
  `active_status` enum('active','onhold','deleted') COLLATE utf8_bin DEFAULT 'active',
  PRIMARY KEY (`id`),
  KEY `idx_job_id` (`job_id`),
  KEY `idx_name` (`name`),
  KEY `idx_type` (`type`),
  KEY `idx_active_status` (`active_status`),
  CONSTRAINT `fk_job_artifact` FOREIGN KEY (`job_id`) REFERENCES `job` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;
/*!40101 SET character_set_client = @saved_cs_client */;

DROP TABLE IF EXISTS `series_signature`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;

/**************************
 * Table: series_signature
 *
 * Each package of performance data submitted to treeherder has a set of properties and associated
 * values that are incorporated into the signature column as a hash. This allows for an easy identification
 * of unique data series suitable for graphing or other analysis applications where identifying data
 * in a series is required.
 *
 * Population Method: dynamic from incoming data
 *
 * Example Data:
 *
 *  signature - References series_signature.signature. A hash of the property values defining a series.
 *  property - The name of a property associated with the signature.
 *  value - The name of a value associated with the property.
 **************************/
CREATE TABLE `series_signature` (
  `signature` varchar(50) COLLATE utf8_bin NOT NULL,
  `property` varchar(50) COLLATE utf8_bin NOT NULL,
  `value` text COLLATE utf8_bin NOT NULL,
  `active_status` enum('active','onhold','deleted') COLLATE utf8_bin DEFAULT 'active',
  KEY `idx_signature` (`signature`),
  KEY `idx_property` (`property`),
  UNIQUE KEY `idx_series` (`signature`, `property`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;
/*!40101 SET character_set_client = @saved_cs_client */;

DROP TABLE IF EXISTS `performance_series`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;

/**************************
 * Table: performance_series
 *
 * Holds time series calculations of mean, std, median, min, and max for each entry in performance_artifact.
 *
 * Population Method: dynamic from incoming data
 *
 * Example Data:
 *
 *  series_signature - References series_signature.signature. A hash of the property values defining a series.
 *  interval_seconds - Interval between storing the data
 *  name - Name of artifact data.
 *  type - json | img | ...
 *  blob - Artifact data
 **************************/
CREATE TABLE `performance_series` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `interval_seconds` int(10) unsigned NOT NULL,
  `series_signature` varchar(50) COLLATE utf8_bin NOT NULL,
  `type` varchar(50) COLLATE utf8_bin NOT NULL,
  `last_updated` int(10) unsigned NOT NULL,
  `blob` mediumblob NOT NULL,
  `active_status` enum('active','onhold','deleted') COLLATE utf8_bin DEFAULT 'active',
  PRIMARY KEY (`id`),
  KEY `idx_interval_seconds` (`interval_seconds`),
  KEY `idx_series_signature` (`series_signature`),
  KEY `idx_last_updated` (`last_updated`),
  KEY `idx_type` (`type`),
  KEY `idx_active_status` (`active_status`),
  UNIQUE KEY `idx_series` (`interval_seconds`, `series_signature`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Table structure for table `job_log_url`
--

DROP TABLE IF EXISTS `job_log_url`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;

/**************************
 * Table: job_log_url
 *
 *  A URL to the log file associated with the job.
 *
 * Population Method: dynamic from incoming data
 *
 * Example Data:
 *
 *  job_id - References job.id
 *  name - Name of log file
 *  url - URL to log file
 *  parse_status - the status of the log parsing
 **************************/
CREATE TABLE `job_log_url` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `job_id` bigint(20) unsigned NOT NULL,
  `name` varchar(50) COLLATE utf8_bin NOT NULL,
  `url` varchar(255) COLLATE utf8_bin NOT NULL,
  `parse_status` enum('pending', 'parsed', 'failed') COLLATE utf8_bin DEFAULT 'pending',
  `active_status` enum('active','onhold','deleted') COLLATE utf8_bin DEFAULT 'active',
  PRIMARY KEY (`id`),
  KEY `idx_job_id` (`job_id`),
  KEY `idx_name` (`name`),
  KEY `idx_active_status` (`active_status`),
  KEY `idx_parse_status` (`parse_status`),
  CONSTRAINT `fk_job_log_url` FOREIGN KEY (`job_id`) REFERENCES `job` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Table structure for table `job_note`
--

DROP TABLE IF EXISTS `job_note`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;

/**************************
 * Table: job_note
 *
 *  Notes associated with a job. Generated manually in the UI.
 *
 * Population Method: manual by admin
 *
 * Example Data:
 *
 *  job_id - References job.id
 *  failure_classification_id - References treeherder_reference_1.failure_classification.id
 *  who - Author of the note
 *  note - Notes associated with the job
 *  note_timestamp - Timestamp associated with the note
 **************************/
CREATE TABLE `job_note` (
  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,
  `job_id` bigint(20) unsigned NOT NULL,
  `failure_classification_id` int(10) unsigned DEFAULT NULL,
  `who` varchar(50) COLLATE utf8_bin NOT NULL,
  `note` mediumtext COLLATE utf8_bin,
  `note_timestamp` int(10) unsigned NOT NULL,
  `active_status` enum('active','onhold','deleted') COLLATE utf8_bin DEFAULT 'active',
  PRIMARY KEY (`id`),
  KEY `idx_job_id` (`job_id`),
  KEY `idx_failure_classification_id` (`failure_classification_id`),
  KEY `idx_who` (`who`),
  KEY `idx_note_timestamp` (`note_timestamp`),
  KEY `idx_active_status` (`active_status`),
  CONSTRAINT `fk_job_note` FOREIGN KEY (`job_id`) REFERENCES `job` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Table structure for table `result_set`
--

DROP TABLE IF EXISTS `result_set`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;

/**************************
 * Table: result_set
 *
 *  A result set is defined by a set of unique repository revisions. Result sets can
 *  have any number of jobs associated with them.
 *
 * Population Method: dynamic from incoming data
 *
 * Example Data:
 *
 *  revision_hash - Hash of any number of revisions associated with the result set
 *  aggregate_id - A id to use for aggregating result_sets. This is primarily used for supporting
 *      a github like pull request work flow but could also be used for any other type of grouping.
 *  author - The author associated with the result_set. May or may not be the author
 *           of an associated revision.
 **************************/
CREATE TABLE `result_set` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `revision_hash` varchar(50) COLLATE utf8_bin NOT NULL,
  `aggregate_id` varchar(50) COLLATE utf8_bin DEFAULT NULL,
  `author` varchar(150) COLLATE utf8_bin NOT NULL,
  `type` varchar(25) DEFAULT NULL,
  `push_timestamp` int(11) unsigned NOT NULL,
  `active_status` enum('active','onhold','deleted') COLLATE utf8_bin DEFAULT 'active',
  PRIMARY KEY (`id`),
  UNIQUE KEY `idx_revision_hash` (`revision_hash`),
  KEY `idx_aggregate_id` (`aggregate_id`),
  KEY `idx_author` (`author`),
  KEY `idx_type` (`type`),
  KEY `idx_push_timestamp` (`push_timestamp`),
  KEY `idx_active_status` (`active_status`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Table structure for table `revision`
--

DROP TABLE IF EXISTS `revision`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;

/**************************
 * Table: revision
 *
 *  List of revisions and their meta data associated with result sets.
 *
 * Population Method: dynamic from incoming data
 *                   ( the meta data will have to come from external web services
 *                     when the data is received )
 *
 * Example Data:
 *
 *  revision - The revision string associated with the repository
 *  author - The author associated with the revision
 *  comments - The comments associated with the revision
 *  commit_timestamp - Timestamp associated with the commit
 **************************/
CREATE TABLE `revision` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `revision` varchar(50) COLLATE utf8_bin NOT NULL,
  `author` varchar(150) COLLATE utf8_bin NOT NULL,
  `comments` text DEFAULT NULL,
  `commit_timestamp` int(11) unsigned default NULL,
  `repository_id` int(11) unsigned NOT NULL,
  `active_status` enum('active','onhold','deleted') COLLATE utf8_bin DEFAULT 'active',
  PRIMARY KEY (`id`),
  UNIQUE KEY `idx_revision` (`revision`, `repository_id`),
  KEY `idx_author` (`author`),
  KEY `idx_commit_timestamp` (`commit_timestamp`),
  KEY `idx_repository_id` (`repository_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Table structure for table `revision_map`
--

DROP TABLE IF EXISTS `revision_map`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;

/**************************
 * Table: revision_map
 *
 *  Maps revisions to their associated result set.
 *
 * Population Method: dynamic from incoming data
 *
 * Example Data:
 *
 *  revision_id - References revision.id
 *  result_set_id - References result_set.id
 **************************/
CREATE TABLE `revision_map` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `revision_id` bigint(20) unsigned NOT NULL,
  `result_set_id` bigint(20) unsigned NOT NULL,
  `active_status` enum('active','onhold','deleted') COLLATE utf8_bin DEFAULT 'active',
  PRIMARY KEY (`id`),
  KEY `idx_revision_id` (`revision_id`),
  KEY `idx_result_set_id` (`result_set_id`),
  KEY `idx_active_status` (`active_status`),
  CONSTRAINT `fk_revision_map` FOREIGN KEY (`revision_id`) REFERENCES `revision` (`id`),
  CONSTRAINT `fk_revision_map_result_set` FOREIGN KEY (`result_set_id`) REFERENCES `result_set` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin;
/*!40101 SET character_set_client = @saved_cs_client */;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2013-02-27  8:54:01
